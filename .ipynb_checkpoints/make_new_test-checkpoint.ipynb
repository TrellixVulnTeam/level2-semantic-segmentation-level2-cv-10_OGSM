{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "300637fe-da37-45e4-8965-5b1b38c9c25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from pycocotools.coco import COCO\n",
    "import os\n",
    "import os.path as osp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3f532f61-f7e9-4319-97c1-bd5c6e1b6e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.51s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "data_dir = '../data'\n",
    "train_path = osp.join(data_dir, 'train.json')\n",
    "train_all_path = osp.join(data_dir, 'train_all.json')\n",
    "org_test_path = osp.join(data_dir, 'test_original.json')\n",
    "new_test_path = osp.join(data_dir, 'test.json')\n",
    "leak_path = osp.join(data_dir, 'batch_03', 'data.json')\n",
    "\n",
    "# train.json\n",
    "with open(train_path, 'r') as f:\n",
    "    train_json = json.load(f)\n",
    "\n",
    "# train_all.json\n",
    "with open(train_all_path, 'r') as f:\n",
    "    train_all_json = json.load(f)\n",
    "    \n",
    "# test_original.json (original)\n",
    "with open(org_test_path, 'r') as f:\n",
    "    org_test_json = json.load(f)\n",
    "    \n",
    "# test.json (new)\n",
    "with open(new_test_path, 'r') as f:\n",
    "    new_test_json = json.load(f)\n",
    "\n",
    "# data.json (leakage)\n",
    "with open(leak_path, 'r') as f:\n",
    "    data_json = json.load(f)\n",
    "    \n",
    "coco_org = COCO(org_test_path)\n",
    "coco_new = COCO(new_test_path)\n",
    "coco_leak = COCO(leak_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "595122e7-cb1d-47a3-b86e-ece7a3c8ac87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of images: 819\n",
      "New number of images: 624\n",
      "Number of leakages: 195\n"
     ]
    }
   ],
   "source": [
    "org_img_fpaths = [img_info['file_name'] for img_info in org_test_json['images']]\n",
    "new_img_fpaths = [img_info['file_name'] for img_info in new_test_json['images']]\n",
    "leak_img_fpaths = sorted(list(set(org_img_fpaths) - set(new_img_fpaths)))\n",
    "\n",
    "print(\"Original number of images: {}\".format(len(org_img_fpaths)))\n",
    "print(\"New number of images: {}\".format(len(new_img_fpaths)))\n",
    "print(\"Number of leakages: {}\".format(len(leak_img_fpaths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "927f7f5a-408a-4110-8b41-4d0ce304d615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [1] 유출된 image가 segmentation이 있는지 확인\n",
    "    # [1.1] data.json (leak_json)에서 leak_img_fpaths에 있는 file_name에 해당하는 img_id 가져오기 [0,10,334,...]\n",
    "    # [1.2] 각 img_id에 해당하는 annotation의 length > 0 이면 data.json 에서 'images'하고 'annotations' 가져와서 합칠 data structure 만들기\n",
    "# [2] train.json과 train_all.json에 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "392e824a-1876-413a-a4e8-28d5c78105ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[1]\n",
      "[2, 3]\n",
      "[4]\n",
      "[5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
      "[21, 22, 23, 24]\n",
      "[25, 26, 27]\n",
      "[28]\n",
      "[29, 30, 31]\n",
      "[32]\n",
      "[33]\n",
      "[34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58]\n"
     ]
    }
   ],
   "source": [
    "leak_img_infos = [img_info for img_info in data_json['images'] if img_info['file_name'] in leak_img_fpaths]\n",
    "leak_img_ids = [img_info['id'] for img_info in leak_img_infos]\n",
    "cnt = 0\n",
    "for idx in range(len(leak_img_ids)):\n",
    "    ann_id = coco_leak.getAnnIds(idx)\n",
    "    ann_infos = coco_leak.loadAnns(ann_id)\n",
    "    print(ann_id)\n",
    "    if cnt > 10:\n",
    "        break\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87aaa7bc-59ec-4c96-b02e-0b008b9cfcc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
